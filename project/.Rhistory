shapiro.test(residuals(model.3.2))
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
model.3.2 = step(model.3.1, direction="both")
#model.3.2 = lm(adr~., train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
model.3.2
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(log(adr)~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr^2-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(log(adr)~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((exp(predicted.adr)-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
plot(train_data$week, summary(model.3.2)$res, type='o')
plot(as.numeric(train_data$week), summary(model.3.2)$res, type='o')
plot(train_data$week, summary(model.3.2)$res, type='o')
dwtest(model.3.2)
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(corrplot)
library(randomForest)
library(leaps)
library(splines)
library(faraway)
library(nlme)
library(MASS)
## read data
data_all = read.csv('stat425_fpdata.csv')
data = data_all[data_all$hotel=='City Hotel',]
data = data[, -1] ## delete variable hotel
colnames(data)[which(names(data) == "arrival_date_year")] <- "year"
colnames(data)[which(names(data) == "arrival_date_week_number")] <- "week"
colnames(data)[which(names(data) == "arrival_date_month")] <- "month"
colnames(data)[which(names(data) == "arrival_date_day_of_month")] <- "day"
colnames(data)[which(names(data) == "stays_in_weekend_nights")] <- "weekend_night"
colnames(data)[which(names(data) == "stays_in_week_nights")] <- "week_night"
colnames(data)[which(names(data) == "reserved_room_type")] <- "room_type"
colnames(data)[which(names(data) == "total_of_special_requests")] <- "requests"
## reset row index
# row.names(data) = 1:nrow(data)
## check missing value
sum(is.na(data))
dim(data)
data = data[which(data$adr>12),]
data = data[which(data$market_segment!='Aviation'),]
data = data[which(data$market_segment!='Complementary'),]
data = data[which(data$room_type!='C'),]
data$is_canceled = as.factor(data$is_canceled)
data$week = as.factor(data$week)
data$year = as.factor(data$year)
#data$arrival_date_day_of_month = as.factor(data$arrival_date_day_of_month)
#data$stay = data$stays_in_week_nights+data$stays_in_weekend_nights
#data$is_popular = ifelse(data$arrival_date_month %in% c('January','February','March'), 0, 1)
data = subset(data,select=-c(month))
## check collinearity
numeric = unlist(lapply(data, is.numeric))
corrplot(cor(data[,numeric]), method="ellipse")
round(cor(data[,numeric]),1)
summary(data)
plot(adr~.,data)
plot(data$lead_time, data$adr)
## train_test_split
set.seed(123)
index = sample(1:nrow(data),size=floor(0.7*nrow(data)))
train_data = data[index,]
test_data = data[-index,]
test_x = subset(test_data, select = -c(adr))
test_y = test_data$adr
## 3.1 simple model
model.3.1 = lm(adr~., train_data)
summary(model.3.1)
plot(model.3.1)
## test error (RMSE)
predicted.adr = predict(model.3.1, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
## 3.1 model diagnostics
## reset index
# row.names(data) = 1:nrow(data)
## check leverage
n=nrow(train_data); p=ncol(train_data);
lev=influence(model.3.1)$hat
halfnorm(lev, 5, labs=row.names(train_data), ylab="Leverages")
sort(lev, decreasing = TRUE)[1:5]
## check outliers
jack=rstudent(model.3.1);
qt(.05/(2*n), n-p-1)
sort(abs(jack), decreasing=TRUE)[1:5]
## Influential observations
cook = cooks.distance(model.3.1)
halfnorm(cook, nlab=5, labs=row.names(train_data), ylab="Cook's distances")
sort(abs(cook), decreasing=TRUE)[1:5]
#max(cook)
deleted = c('1644', '1722', '1700')
train_data = train_data[!row.names(train_data) %in% deleted,]
## constant variance test
bptest(model.3.1)
## normality
shapiro.test(residuals(model.3.1))
## boxcox
bc = boxcox(model.3.1)
bc$x[ozbc$y == max(ozbc$y)]
bc$x[ozbc$y == max(bc$y)]
bc$x[bc$y == max(bc$y)]
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr^(1/4)~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr^4-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
boxcox(model.3.2)
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(corrplot)
library(randomForest)
library(leaps)
library(splines)
library(faraway)
library(nlme)
library(MASS)
## read data
data_all = read.csv('stat425_fpdata.csv')
data = data_all[data_all$hotel=='City Hotel',]
data = data[, -1] ## delete variable hotel
colnames(data)[which(names(data) == "arrival_date_year")] <- "year"
colnames(data)[which(names(data) == "arrival_date_week_number")] <- "week"
colnames(data)[which(names(data) == "arrival_date_month")] <- "month"
colnames(data)[which(names(data) == "arrival_date_day_of_month")] <- "day"
colnames(data)[which(names(data) == "stays_in_weekend_nights")] <- "weekend_night"
colnames(data)[which(names(data) == "stays_in_week_nights")] <- "week_night"
colnames(data)[which(names(data) == "reserved_room_type")] <- "room_type"
colnames(data)[which(names(data) == "total_of_special_requests")] <- "requests"
## reset row index
# row.names(data) = 1:nrow(data)
## check missing value
sum(is.na(data))
dim(data)
data = data[which(data$adr>12),]
data = data[which(data$market_segment!='Aviation'),]
data = data[which(data$market_segment!='Complementary'),]
data = data[which(data$room_type!='C'),]
data$is_canceled = as.factor(data$is_canceled)
data$week = as.factor(data$week)
data$year = as.factor(data$year)
#data$arrival_date_day_of_month = as.factor(data$arrival_date_day_of_month)
#data$stay = data$stays_in_week_nights+data$stays_in_weekend_nights
#data$is_popular = ifelse(data$arrival_date_month %in% c('January','February','March'), 0, 1)
data = subset(data,select=-c(month))
## check collinearity
numeric = unlist(lapply(data, is.numeric))
corrplot(cor(data[,numeric]), method="ellipse")
round(cor(data[,numeric]),1)
summary(data)
plot(adr~.,data)
plot(data$lead_time, data$adr)
## train_test_split
set.seed(123)
index = sample(1:nrow(data),size=floor(0.7*nrow(data)))
train_data = data[index,]
test_data = data[-index,]
test_x = subset(test_data, select = -c(adr))
test_y = test_data$adr
## 3.1 simple model
model.3.1 = lm(adr~., train_data)
summary(model.3.1)
plot(model.3.1)
## test error (RMSE)
predicted.adr = predict(model.3.1, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
which(is.na(train_data))
which(is.na(predicted.adr))
## 3.1 model diagnostics
## reset index
# row.names(data) = 1:nrow(data)
## check leverage
n=nrow(train_data); p=ncol(train_data);
lev=influence(model.3.1)$hat
halfnorm(lev, 5, labs=row.names(train_data), ylab="Leverages")
sort(lev, decreasing = TRUE)[1:5]
## check outliers
jack=rstudent(model.3.1);
qt(.05/(2*n), n-p-1)
sort(abs(jack), decreasing=TRUE)[1:5]
## Influential observations
cook = cooks.distance(model.3.1)
halfnorm(cook, nlab=5, labs=row.names(train_data), ylab="Cook's distances")
sort(abs(cook), decreasing=TRUE)[1:5]
#max(cook)
deleted = c('1644', '1722', '1700')
train_data = train_data[!row.names(train_data) %in% deleted,]
## constant variance test
bptest(model.3.1)
## normality
shapiro.test(residuals(model.3.1))
## boxcox
bc = boxcox(model.3.1)
bc$x[bc$y == max(bc$y)]
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr^(1/4)~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr^4-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(corrplot)
library(randomForest)
library(leaps)
library(splines)
library(faraway)
library(nlme)
library(MASS)
## read data
data_all = read.csv('stat425_fpdata.csv')
data = data_all[data_all$hotel=='City Hotel',]
data = data[, -1] ## delete variable hotel
colnames(data)[which(names(data) == "arrival_date_year")] <- "year"
colnames(data)[which(names(data) == "arrival_date_week_number")] <- "week"
colnames(data)[which(names(data) == "arrival_date_month")] <- "month"
colnames(data)[which(names(data) == "arrival_date_day_of_month")] <- "day"
colnames(data)[which(names(data) == "stays_in_weekend_nights")] <- "weekend_night"
colnames(data)[which(names(data) == "stays_in_week_nights")] <- "week_night"
colnames(data)[which(names(data) == "reserved_room_type")] <- "room_type"
colnames(data)[which(names(data) == "total_of_special_requests")] <- "requests"
## reset row index
# row.names(data) = 1:nrow(data)
## check missing value
sum(is.na(data))
dim(data)
data = data[which(data$adr>12),]
data = data[which(data$market_segment!='Aviation'),]
data = data[which(data$market_segment!='Complementary'),]
data = data[which(data$room_type!='C'),]
data$is_canceled = as.factor(data$is_canceled)
data$week = as.factor(data$week)
data$year = as.factor(data$year)
#data$arrival_date_day_of_month = as.factor(data$arrival_date_day_of_month)
#data$stay = data$stays_in_week_nights+data$stays_in_weekend_nights
#data$is_popular = ifelse(data$arrival_date_month %in% c('January','February','March'), 0, 1)
data = subset(data,select=-c(month))
## check collinearity
numeric = unlist(lapply(data, is.numeric))
corrplot(cor(data[,numeric]), method="ellipse")
round(cor(data[,numeric]),1)
summary(data)
plot(adr~.,data)
plot(data$lead_time, data$adr)
## train_test_split
set.seed(123)
index = sample(1:nrow(data),size=floor(0.7*nrow(data)))
train_data = data[index,]
test_data = data[-index,]
test_x = subset(test_data, select = -c(adr))
test_y = test_data$adr
## 3.1 simple model
model.3.1 = lm(adr~., train_data)
summary(model.3.1)
plot(model.3.1)
## test error (RMSE)
predicted.adr = predict(model.3.1, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
## 3.1 model diagnostics
## reset index
# row.names(data) = 1:nrow(data)
## check leverage
n=nrow(train_data); p=ncol(train_data);
lev=influence(model.3.1)$hat
halfnorm(lev, 5, labs=row.names(train_data), ylab="Leverages")
sort(lev, decreasing = TRUE)[1:5]
## check outliers
jack=rstudent(model.3.1);
qt(.05/(2*n), n-p-1)
sort(abs(jack), decreasing=TRUE)[1:5]
## Influential observations
cook = cooks.distance(model.3.1)
halfnorm(cook, nlab=5, labs=row.names(train_data), ylab="Cook's distances")
sort(abs(cook), decreasing=TRUE)[1:5]
#max(cook)
#deleted = c('1644', '1722', '1700')
#train_data = train_data[!row.names(train_data) %in% deleted,]
## constant variance test
bptest(model.3.1)
## normality
shapiro.test(residuals(model.3.1))
## boxcox
bc = boxcox(model.3.1)
bc$x[bc$y == max(bc$y)]
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr^(1/4)~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr^4-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(corrplot)
library(randomForest)
library(leaps)
library(splines)
library(faraway)
library(nlme)
library(MASS)
## read data
data_all = read.csv('stat425_fpdata.csv')
data = data_all[data_all$hotel=='City Hotel',]
data = data[, -1] ## delete variable hotel
colnames(data)[which(names(data) == "arrival_date_year")] <- "year"
colnames(data)[which(names(data) == "arrival_date_week_number")] <- "week"
colnames(data)[which(names(data) == "arrival_date_month")] <- "month"
colnames(data)[which(names(data) == "arrival_date_day_of_month")] <- "day"
colnames(data)[which(names(data) == "stays_in_weekend_nights")] <- "weekend_night"
colnames(data)[which(names(data) == "stays_in_week_nights")] <- "week_night"
colnames(data)[which(names(data) == "reserved_room_type")] <- "room_type"
colnames(data)[which(names(data) == "total_of_special_requests")] <- "requests"
## reset row index
# row.names(data) = 1:nrow(data)
## check missing value
sum(is.na(data))
dim(data)
data = data[which(data$adr>12),]
data = data[which(data$market_segment!='Aviation'),]
data = data[which(data$market_segment!='Complementary'),]
data = data[which(data$room_type!='C'),]
data$is_canceled = as.factor(data$is_canceled)
data$week = as.factor(data$week)
data$year = as.factor(data$year)
#data$arrival_date_day_of_month = as.factor(data$arrival_date_day_of_month)
#data$stay = data$stays_in_week_nights+data$stays_in_weekend_nights
#data$is_popular = ifelse(data$arrival_date_month %in% c('January','February','March'), 0, 1)
data = subset(data,select=-c(month))
## check collinearity
numeric = unlist(lapply(data, is.numeric))
corrplot(cor(data[,numeric]), method="ellipse")
round(cor(data[,numeric]),1)
summary(data)
plot(adr~.,data)
plot(data$lead_time, data$adr)
## train_test_split
set.seed(123)
index = sample(1:nrow(data),size=floor(0.7*nrow(data)))
train_data = data[index,]
test_data = data[-index,]
test_x = subset(test_data, select = -c(adr))
test_y = test_data$adr
## 3.1 simple model
model.3.1 = lm(adr~., train_data)
summary(model.3.1)
plot(model.3.1)
## test error (RMSE)
predicted.adr = predict(model.3.1, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
## 3.1 model diagnostics
## reset index
# row.names(data) = 1:nrow(data)
## check leverage
n=nrow(train_data); p=ncol(train_data);
lev=influence(model.3.1)$hat
halfnorm(lev, 5, labs=row.names(train_data), ylab="Leverages")
sort(lev, decreasing = TRUE)[1:5]
## check outliers
jack=rstudent(model.3.1);
qt(.05/(2*n), n-p-1)
sort(abs(jack), decreasing=TRUE)[1:5]
## Influential observations
cook = cooks.distance(model.3.1)
halfnorm(cook, nlab=5, labs=row.names(train_data), ylab="Cook's distances")
sort(abs(cook), decreasing=TRUE)[1:5]
#max(cook)
#deleted = c('1644', '1722', '1700')
#train_data = train_data[!row.names(train_data) %in% deleted,]
## constant variance test
bptest(model.3.1)
## normality
shapiro.test(residuals(model.3.1))
## boxcox
bc = boxcox(model.3.1)
bc$x[bc$y == max(bc$y)]
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr^(1/5)~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr^5-test_y)^2/length(test_y)))
plot(model.3.2)
## constant variance test
bptest(model.3.2)
## normality
shapiro.test(residuals(model.3.2))
boxcox(model.3.2)
## 3.2 linear regression
## refit with new data
model.3.1 = lm(adr~., train_data)
## variable selection
step(model.3.1, direction="both")
model.3.2 = lm(adr~is_canceled + lead_time + year + week + adults +
children + meal + market_segment + room_type + customer_type +
requests, train_data)
#summary(model.3.2)
## test error (RMSE)
predicted.adr = predict(model.3.2, newdata=test_x)
sqrt(sum((predicted.adr-test_y)^2/length(test_y)))
plot(model.3.2)
